{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3:"
      ],
      "metadata": {
        "id": "4HPgAclZwhlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist  # Example dataset, replace with your dataset\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "train_images = train_images.reshape((train_images.shape[0], -1))\n",
        "test_images = test_images.reshape((test_images.shape[0], -1))\n",
        "\n",
        "# Define the neural network architecture\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=100, batch_size=32, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2T6CF1BROMF",
        "outputId": "ab2886a6-18be-4de5-db62-1596677b3b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: -8292140.0000 - accuracy: 0.1124 - val_loss: -31822136.0000 - val_accuracy: 0.1135\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -96663624.0000 - accuracy: 0.1124 - val_loss: -191103376.0000 - val_accuracy: 0.1135\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -334417824.0000 - accuracy: 0.1124 - val_loss: -521826048.0000 - val_accuracy: 0.1135\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -754258944.0000 - accuracy: 0.1124 - val_loss: -1052900032.0000 - val_accuracy: 0.1135\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -1386980736.0000 - accuracy: 0.1124 - val_loss: -1818879872.0000 - val_accuracy: 0.1135\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -2267887104.0000 - accuracy: 0.1124 - val_loss: -2853752320.0000 - val_accuracy: 0.1135\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -3426070016.0000 - accuracy: 0.1124 - val_loss: -4188002560.0000 - val_accuracy: 0.1135\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -4897045504.0000 - accuracy: 0.1124 - val_loss: -5857150976.0000 - val_accuracy: 0.1135\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -6712802304.0000 - accuracy: 0.1124 - val_loss: -7895852032.0000 - val_accuracy: 0.1135\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -8906565632.0000 - accuracy: 0.1124 - val_loss: -10334772224.0000 - val_accuracy: 0.1135\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -11505564672.0000 - accuracy: 0.1124 - val_loss: -13202219008.0000 - val_accuracy: 0.1135\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -14542157824.0000 - accuracy: 0.1124 - val_loss: -16536449024.0000 - val_accuracy: 0.1135\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -18054432768.0000 - accuracy: 0.1124 - val_loss: -20368074752.0000 - val_accuracy: 0.1135\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -22065764352.0000 - accuracy: 0.1124 - val_loss: -24721944576.0000 - val_accuracy: 0.1135\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -26606393344.0000 - accuracy: 0.1124 - val_loss: -29632475136.0000 - val_accuracy: 0.1135\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -31709229056.0000 - accuracy: 0.1124 - val_loss: -35132203008.0000 - val_accuracy: 0.1135\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -37417107456.0000 - accuracy: 0.1124 - val_loss: -41272897536.0000 - val_accuracy: 0.1135\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -43744493568.0000 - accuracy: 0.1124 - val_loss: -48050831360.0000 - val_accuracy: 0.1135\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -50723348480.0000 - accuracy: 0.1124 - val_loss: -55514296320.0000 - val_accuracy: 0.1135\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -58398617600.0000 - accuracy: 0.1124 - val_loss: -63696490496.0000 - val_accuracy: 0.1135\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -66787295232.0000 - accuracy: 0.1124 - val_loss: -72621826048.0000 - val_accuracy: 0.1135\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -75918843904.0000 - accuracy: 0.1124 - val_loss: -82331901952.0000 - val_accuracy: 0.1135\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -85842132992.0000 - accuracy: 0.1124 - val_loss: -92855746560.0000 - val_accuracy: 0.1135\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -96569114624.0000 - accuracy: 0.1124 - val_loss: -104227274752.0000 - val_accuracy: 0.1135\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -108145836032.0000 - accuracy: 0.1124 - val_loss: -116447223808.0000 - val_accuracy: 0.1135\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -120558346240.0000 - accuracy: 0.1124 - val_loss: -129565097984.0000 - val_accuracy: 0.1135\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -133903736832.0000 - accuracy: 0.1124 - val_loss: -143646703616.0000 - val_accuracy: 0.1135\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -148180992000.0000 - accuracy: 0.1124 - val_loss: -158688018432.0000 - val_accuracy: 0.1135\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -163419947008.0000 - accuracy: 0.1124 - val_loss: -174721171456.0000 - val_accuracy: 0.1135\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -179635879936.0000 - accuracy: 0.1124 - val_loss: -191773196288.0000 - val_accuracy: 0.1135\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -196889886720.0000 - accuracy: 0.1124 - val_loss: -209898700800.0000 - val_accuracy: 0.1135\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -215144251392.0000 - accuracy: 0.1124 - val_loss: -229035540480.0000 - val_accuracy: 0.1135\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -234480779264.0000 - accuracy: 0.1124 - val_loss: -249340346368.0000 - val_accuracy: 0.1135\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -254995382272.0000 - accuracy: 0.1124 - val_loss: -270828748800.0000 - val_accuracy: 0.1135\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -276631355392.0000 - accuracy: 0.1124 - val_loss: -293479514112.0000 - val_accuracy: 0.1135\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -299422121984.0000 - accuracy: 0.1124 - val_loss: -317334585344.0000 - val_accuracy: 0.1135\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -323420192768.0000 - accuracy: 0.1124 - val_loss: -342392832000.0000 - val_accuracy: 0.1135\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -348627959808.0000 - accuracy: 0.1124 - val_loss: -368747675648.0000 - val_accuracy: 0.1135\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -375118200832.0000 - accuracy: 0.1124 - val_loss: -396408422400.0000 - val_accuracy: 0.1135\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -402866700288.0000 - accuracy: 0.1124 - val_loss: -425357672448.0000 - val_accuracy: 0.1135\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -431958982656.0000 - accuracy: 0.1124 - val_loss: -455732068352.0000 - val_accuracy: 0.1135\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -462401339392.0000 - accuracy: 0.1124 - val_loss: -487459192832.0000 - val_accuracy: 0.1135\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -494219984896.0000 - accuracy: 0.1124 - val_loss: -520622145536.0000 - val_accuracy: 0.1135\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -527492349952.0000 - accuracy: 0.1124 - val_loss: -555278794752.0000 - val_accuracy: 0.1135\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -562146836480.0000 - accuracy: 0.1124 - val_loss: -591332376576.0000 - val_accuracy: 0.1135\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -598292824064.0000 - accuracy: 0.1124 - val_loss: -628964130816.0000 - val_accuracy: 0.1135\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -635927461888.0000 - accuracy: 0.1124 - val_loss: -668113436672.0000 - val_accuracy: 0.1135\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -675130769408.0000 - accuracy: 0.1124 - val_loss: -708877680640.0000 - val_accuracy: 0.1135\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -715924635648.0000 - accuracy: 0.1124 - val_loss: -751287926784.0000 - val_accuracy: 0.1135\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -758248177664.0000 - accuracy: 0.1124 - val_loss: -795236630528.0000 - val_accuracy: 0.1135\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -802168766464.0000 - accuracy: 0.1124 - val_loss: -840850866176.0000 - val_accuracy: 0.1135\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -847796109312.0000 - accuracy: 0.1124 - val_loss: -888271667200.0000 - val_accuracy: 0.1135\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -895024758784.0000 - accuracy: 0.1124 - val_loss: -937223520256.0000 - val_accuracy: 0.1135\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -943964160000.0000 - accuracy: 0.1124 - val_loss: -988043673600.0000 - val_accuracy: 0.1135\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -994731687936.0000 - accuracy: 0.1124 - val_loss: -1040701718528.0000 - val_accuracy: 0.1135\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -1047235330048.0000 - accuracy: 0.1124 - val_loss: -1095156957184.0000 - val_accuracy: 0.1135\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -1101473382400.0000 - accuracy: 0.1124 - val_loss: -1151365152768.0000 - val_accuracy: 0.1135\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -1157571280896.0000 - accuracy: 0.1124 - val_loss: -1209544212480.0000 - val_accuracy: 0.1135\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -1215614287872.0000 - accuracy: 0.1124 - val_loss: -1269710323712.0000 - val_accuracy: 0.1135\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -1275487715328.0000 - accuracy: 0.1124 - val_loss: -1331697418240.0000 - val_accuracy: 0.1135\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -1337345966080.0000 - accuracy: 0.1124 - val_loss: -1395761086464.0000 - val_accuracy: 0.1135\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -1401158893568.0000 - accuracy: 0.1124 - val_loss: -1461786247168.0000 - val_accuracy: 0.1135\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -1466746273792.0000 - accuracy: 0.1124 - val_loss: -1529651658752.0000 - val_accuracy: 0.1135\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -1534442078208.0000 - accuracy: 0.1124 - val_loss: -1599772033024.0000 - val_accuracy: 0.1135\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -1604343955456.0000 - accuracy: 0.1124 - val_loss: -1672117092352.0000 - val_accuracy: 0.1135\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -1676175867904.0000 - accuracy: 0.1124 - val_loss: -1746362957824.0000 - val_accuracy: 0.1135\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -1750092611584.0000 - accuracy: 0.1124 - val_loss: -1822815027200.0000 - val_accuracy: 0.1135\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -1826155921408.0000 - accuracy: 0.1124 - val_loss: -1901514719232.0000 - val_accuracy: 0.1135\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -1904394633216.0000 - accuracy: 0.1124 - val_loss: -1982310776832.0000 - val_accuracy: 0.1135\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -1984716996608.0000 - accuracy: 0.1124 - val_loss: -2065427595264.0000 - val_accuracy: 0.1135\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -2067279118336.0000 - accuracy: 0.1124 - val_loss: -2150666862592.0000 - val_accuracy: 0.1135\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -2152214036480.0000 - accuracy: 0.1124 - val_loss: -2238490083328.0000 - val_accuracy: 0.1135\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -2239292243968.0000 - accuracy: 0.1124 - val_loss: -2328420941824.0000 - val_accuracy: 0.1135\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -2328758845440.0000 - accuracy: 0.1124 - val_loss: -2420809662464.0000 - val_accuracy: 0.1135\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -2420512915456.0000 - accuracy: 0.1124 - val_loss: -2515570262016.0000 - val_accuracy: 0.1135\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -2514672418816.0000 - accuracy: 0.1124 - val_loss: -2612761985024.0000 - val_accuracy: 0.1135\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -2611207733248.0000 - accuracy: 0.1124 - val_loss: -2712424939520.0000 - val_accuracy: 0.1135\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -2710088450048.0000 - accuracy: 0.1124 - val_loss: -2814527930368.0000 - val_accuracy: 0.1135\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -2811469758464.0000 - accuracy: 0.1124 - val_loss: -2919179223040.0000 - val_accuracy: 0.1135\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -2915427418112.0000 - accuracy: 0.1124 - val_loss: -3026447761408.0000 - val_accuracy: 0.1135\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -3021707149312.0000 - accuracy: 0.1124 - val_loss: -3135964446720.0000 - val_accuracy: 0.1135\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -3130621689856.0000 - accuracy: 0.1124 - val_loss: -3248420290560.0000 - val_accuracy: 0.1135\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -3242249158656.0000 - accuracy: 0.1124 - val_loss: -3363606626304.0000 - val_accuracy: 0.1135\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -3356482600960.0000 - accuracy: 0.1124 - val_loss: -3481362235392.0000 - val_accuracy: 0.1135\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -3473022386176.0000 - accuracy: 0.1124 - val_loss: -3601453023232.0000 - val_accuracy: 0.1135\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -3592379170816.0000 - accuracy: 0.1124 - val_loss: -3724627935232.0000 - val_accuracy: 0.1135\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -3714542469120.0000 - accuracy: 0.1124 - val_loss: -3850474618880.0000 - val_accuracy: 0.1135\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -3839183028224.0000 - accuracy: 0.1124 - val_loss: -3979038162944.0000 - val_accuracy: 0.1135\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -3966878089216.0000 - accuracy: 0.1124 - val_loss: -4110691336192.0000 - val_accuracy: 0.1135\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -4097125384192.0000 - accuracy: 0.1124 - val_loss: -4244809711616.0000 - val_accuracy: 0.1135\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -4230151667712.0000 - accuracy: 0.1124 - val_loss: -4381988618240.0000 - val_accuracy: 0.1135\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -4366115799040.0000 - accuracy: 0.1124 - val_loss: -4521920036864.0000 - val_accuracy: 0.1135\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -4504696651776.0000 - accuracy: 0.1124 - val_loss: -4664686804992.0000 - val_accuracy: 0.1135\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -4646431096832.0000 - accuracy: 0.1124 - val_loss: -4810831560704.0000 - val_accuracy: 0.1135\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -4791122001920.0000 - accuracy: 0.1124 - val_loss: -4959833161728.0000 - val_accuracy: 0.1135\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -4938657693696.0000 - accuracy: 0.1124 - val_loss: -5111721492480.0000 - val_accuracy: 0.1135\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -5089158758400.0000 - accuracy: 0.1124 - val_loss: -5266825805824.0000 - val_accuracy: 0.1135\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -5242844872704.0000 - accuracy: 0.1124 - val_loss: -5425037049856.0000 - val_accuracy: 0.1135\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -5399619043328.0000 - accuracy: 0.1124 - val_loss: -5586395070464.0000 - val_accuracy: 0.1135\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -5559442472960.0000 - accuracy: 0.1124 - val_loss: -5750832758784.0000 - val_accuracy: 0.1135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c8f8df98dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist  # Example dataset, replace with your dataset\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "train_images = train_images.reshape((train_images.shape[0], -1))\n",
        "test_images = test_images.reshape((test_images.shape[0], -1))\n",
        "\n",
        "# Define the neural network architecture\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnZ6yRmeT3Gr",
        "outputId": "c81c2eaf-4a50-491b-d31e-3d3a0ebf3311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -9476486.0000 - accuracy: 0.1123 - val_loss: -36962568.0000 - val_accuracy: 0.1135\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -113555056.0000 - accuracy: 0.1124 - val_loss: -224598480.0000 - val_accuracy: 0.1135\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -391707136.0000 - accuracy: 0.1124 - val_loss: -611158272.0000 - val_accuracy: 0.1135\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: -884113728.0000 - accuracy: 0.1124 - val_loss: -1234836992.0000 - val_accuracy: 0.1135\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -1628714112.0000 - accuracy: 0.1124 - val_loss: -2135920768.0000 - val_accuracy: 0.1135\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: -2661937920.0000 - accuracy: 0.1124 - val_loss: -3349730816.0000 - val_accuracy: 0.1135\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: -4023771648.0000 - accuracy: 0.1124 - val_loss: -4919401472.0000 - val_accuracy: 0.1135\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -5750418432.0000 - accuracy: 0.1124 - val_loss: -6876521472.0000 - val_accuracy: 0.1135\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: -7883312128.0000 - accuracy: 0.1124 - val_loss: -9275021312.0000 - val_accuracy: 0.1135\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: -10458409984.0000 - accuracy: 0.1124 - val_loss: -12135690240.0000 - val_accuracy: 0.1135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c8f8d659660>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4:"
      ],
      "metadata": {
        "id": "uJ9JyYrXwcZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformed LeNet-5"
      ],
      "metadata": {
        "id": "E1hVlyicJEdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Check if running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Transformation for LeNet-5\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4388, 0.4235, 0.4789], std=[0.1987, 0.2012, 0.1977])\n",
        "])\n",
        "\n",
        "# Transformed/Adjusted LeNet-5 for SVHN\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)  # Adjusting the layers for 3-channel input\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*6*6, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.tanh(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*6*6)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Loading the SVHN dataset\n",
        "train_dataset = datasets.SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "subset_indices = np.random.choice(len(train_dataset), len(train_dataset) // 4, replace=False)\n",
        "dataset_subset = torch.utils.data.Subset(train_dataset, subset_indices)\n",
        "train_size = int(0.8 * len(dataset_subset))\n",
        "test_size = len(dataset_subset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset_subset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Device specification\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training and evaluation\n",
        "def training_and_evaluating(model, train_loader, test_loader):\n",
        "    print('Training and Evaluating the model')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    for epoch in range(15):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                images, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        print(f'Accuracy of the adjusted LeNEt-5 on the test images set: {100 * correct // total} %')\n",
        "\n",
        "# Model selection and training\n",
        "def selecting_model():\n",
        "    print('Starting the training-----------------------')\n",
        "    print('Training LeNet-5 network on the SVHN dataset')\n",
        "    model = LeNet5().to(device)\n",
        "    training_and_evaluating(model, train_loader, test_loader)\n",
        "    print('Training Ended and Evaluating the model')\n",
        "    print('Execution has been completed----------------')\n",
        "\n",
        "# Execute the training process\n",
        "selecting_model()\n"
      ],
      "metadata": {
        "id": "6uY4OawpwryP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea05ae96-0174-459f-a68a-b40331919942"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Starting the training-----------------------\n",
            "Training LeNet-5 network on the SVHN dataset\n",
            "Training and Evaluating the model\n",
            "Epoch 1, Loss: 2.260485726152445\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 18 %\n",
            "Epoch 2, Loss: 2.2246187347512056\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 20 %\n",
            "Epoch 3, Loss: 2.1864857876665207\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 24 %\n",
            "Epoch 4, Loss: 2.0446674545258934\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 34 %\n",
            "Epoch 5, Loss: 1.7166549042843315\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 46 %\n",
            "Epoch 6, Loss: 1.3349888237542982\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 61 %\n",
            "Epoch 7, Loss: 1.0584304996452998\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 69 %\n",
            "Epoch 8, Loss: 0.8771918843536919\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 76 %\n",
            "Epoch 9, Loss: 0.7483230878041821\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 79 %\n",
            "Epoch 10, Loss: 0.662967635131559\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 80 %\n",
            "Epoch 11, Loss: 0.5986317606341891\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 82 %\n",
            "Epoch 12, Loss: 0.5530228412112295\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 82 %\n",
            "Epoch 13, Loss: 0.5192840070703665\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 83 %\n",
            "Epoch 14, Loss: 0.49107878515293507\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 84 %\n",
            "Epoch 15, Loss: 0.4697536708681344\n",
            "Accuracy of the adjusted LeNEt-5 on the test images set: 84 %\n",
            "Training Ended and Evaluating the model\n",
            "Execution has been completed----------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For 'AlexNet', 'VGG16', 'ResNet18', 'ResNet50', 'ResNet101'"
      ],
      "metadata": {
        "id": "xeAhUnTNKtFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import SVHN\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from google.colab import drive\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformation for AlexNet, VGG16, and ResNet\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the SVHN dataset\n",
        "def load_dataset():\n",
        "    full_dataset = SVHN(root='./data', split='train', transform=transform, download=True)\n",
        "    subset_indices = np.random.choice(len(full_dataset), len(full_dataset) // 4, replace=False)\n",
        "    dataset_subset = Subset(full_dataset, subset_indices)\n",
        "    train_size = int(0.8 * len(dataset_subset))\n",
        "    test_size = len(dataset_subset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(dataset_subset, [train_size, test_size])\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Get the modified model\n",
        "def get_modified_model(model_name):\n",
        "    print(f\"Loading {model_name}\")\n",
        "    if model_name == 'alexnet':\n",
        "        model = models.alexnet(pretrained=True)\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
        "    elif model_name == 'vgg16':\n",
        "        model = models.vgg16(pretrained=True)\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
        "    elif model_name in ['resnet18', 'resnet50', 'resnet101']:\n",
        "        model = getattr(models, model_name)(pretrained=True)\n",
        "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model name\")\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "# Training and evaluation\n",
        "def train_and_evaluate(model, train_loader, test_loader):\n",
        "    print('Training and Evaluating the model')\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                images, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
        "\n",
        "# Choose and train model\n",
        "def choose_and_train():\n",
        "    model_names = ['alexnet', 'vgg16', 'resnet18', 'resnet50', 'resnet101']\n",
        "    for model_name in model_names:\n",
        "        print('-------------------------------------')\n",
        "        print(f\"Training and evaluating {model_name}\")\n",
        "        train_loader, test_loader = load_dataset()\n",
        "        model = get_modified_model(model_name)\n",
        "        train_and_evaluate(model, train_loader, test_loader)\n",
        "        print('Finished Training and Evaluating the model')\n",
        "        print('-------------------------------------')\n",
        "\n",
        "# Execute model selection and training\n",
        "if __name__ == \"__main__\":\n",
        "    choose_and_train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNzD0x81K-Yj",
        "outputId": "63b0993b-45bc-4b6a-8bdd-fd1d92b5a181"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "Training and evaluating alexnet\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 182040794/182040794 [00:07<00:00, 23546518.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading alexnet\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 144MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and Evaluating the model\n",
            "Epoch 1, Loss: 2.4505471339912916\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 2, Loss: 2.241458427437528\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 3, Loss: 2.2408821135108647\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 4, Loss: 2.2398746201044606\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 5, Loss: 2.239052324836431\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 6, Loss: 2.238869343262052\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 7, Loss: 2.23873921981545\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 8, Loss: 2.2381779491641116\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 9, Loss: 2.238525573863733\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 10, Loss: 2.2386259834839266\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Finished Training and Evaluating the model\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "Training and evaluating vgg16\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Loading vgg16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:07<00:00, 75.1MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and Evaluating the model\n",
            "Epoch 1, Loss: 15.249923662327262\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 2, Loss: 2.2953814741825953\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 3, Loss: 2.24004292696324\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 4, Loss: 2.281091994073193\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 5, Loss: 5421.818341276011\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 6, Loss: 8848598.966155104\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 7, Loss: 94.83870882446588\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 8, Loss: 19.176557255624164\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 9, Loss: 411.68384498071464\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 10, Loss: 2.2380809534064547\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Finished Training and Evaluating the model\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "Training and evaluating resnet18\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Loading resnet18\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 143MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and Evaluating the model\n",
            "Epoch 1, Loss: 1.5649416123935749\n",
            "Accuracy of the network on the test images: 81 %\n",
            "Epoch 2, Loss: 0.4165521112461798\n",
            "Accuracy of the network on the test images: 89 %\n",
            "Epoch 3, Loss: 0.3052966509778947\n",
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 4, Loss: 0.2610289757363661\n",
            "Accuracy of the network on the test images: 88 %\n",
            "Epoch 5, Loss: 0.21239463768606623\n",
            "Accuracy of the network on the test images: 90 %\n",
            "Epoch 6, Loss: 0.18142753100128414\n",
            "Accuracy of the network on the test images: 89 %\n",
            "Epoch 7, Loss: 0.16105057557792643\n",
            "Accuracy of the network on the test images: 90 %\n",
            "Epoch 8, Loss: 0.1263657102247448\n",
            "Accuracy of the network on the test images: 89 %\n",
            "Epoch 9, Loss: 0.10386876524202363\n",
            "Accuracy of the network on the test images: 91 %\n",
            "Epoch 10, Loss: 0.08371157860729078\n",
            "Accuracy of the network on the test images: 91 %\n",
            "Finished Training and Evaluating the model\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "Training and evaluating resnet50\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Loading resnet50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 165MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and Evaluating the model\n",
            "Epoch 1, Loss: 2.3148175920461465\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 2, Loss: 2.2502887759146213\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 3, Loss: 2.2136622360179516\n",
            "Accuracy of the network on the test images: 16 %\n",
            "Epoch 4, Loss: 1.6436867932565347\n",
            "Accuracy of the network on the test images: 52 %\n",
            "Epoch 5, Loss: 0.7805446008927958\n",
            "Accuracy of the network on the test images: 79 %\n",
            "Epoch 6, Loss: 0.5082007900986609\n",
            "Accuracy of the network on the test images: 81 %\n",
            "Epoch 7, Loss: 0.39830726001200195\n",
            "Accuracy of the network on the test images: 85 %\n",
            "Epoch 8, Loss: 0.34682689350114637\n",
            "Accuracy of the network on the test images: 85 %\n",
            "Epoch 9, Loss: 0.3053276071479487\n",
            "Accuracy of the network on the test images: 85 %\n",
            "Epoch 10, Loss: 0.2778773761667539\n",
            "Accuracy of the network on the test images: 87 %\n",
            "Finished Training and Evaluating the model\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "Training and evaluating resnet101\n",
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Loading resnet101\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 93.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Evaluating the model\n",
            "Epoch 1, Loss: 2.296499730197623\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 2, Loss: 2.244942284046823\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 3, Loss: 2.238801780225929\n",
            "Accuracy of the network on the test images: 19 %\n",
            "Epoch 4, Loss: 2.021801826735251\n",
            "Accuracy of the network on the test images: 35 %\n",
            "Epoch 5, Loss: 1.054854706255109\n",
            "Accuracy of the network on the test images: 75 %\n",
            "Epoch 6, Loss: 0.549926346306197\n",
            "Accuracy of the network on the test images: 77 %\n",
            "Epoch 7, Loss: 0.414735689824325\n",
            "Accuracy of the network on the test images: 85 %\n",
            "Epoch 8, Loss: 0.3725390673724845\n",
            "Accuracy of the network on the test images: 88 %\n",
            "Epoch 9, Loss: 0.33493550739954653\n",
            "Accuracy of the network on the test images: 83 %\n",
            "Epoch 10, Loss: 0.3021253571890327\n",
            "Accuracy of the network on the test images: 86 %\n",
            "Finished Training and Evaluating the model\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9raiR7xbNuWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}